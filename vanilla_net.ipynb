{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = Sequential()\n",
    "# add first hidden layer (784 layer assumed)\n",
    "model.add(Dense(500, input_shape=(784,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# add second hidden layer\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data from MNIST Database\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# massage data\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = (X_train.astype('float32'))/255\n",
    "X_test = (X_test.astype('float32'))/255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 7s - loss: 0.0124 - acc: 0.9179 - val_loss: 0.0054 - val_acc: 0.9646\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 7s - loss: 0.0057 - acc: 0.9629 - val_loss: 0.0044 - val_acc: 0.9708\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 7s - loss: 0.0043 - acc: 0.9732 - val_loss: 0.0036 - val_acc: 0.9768\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 7s - loss: 0.0035 - acc: 0.9777 - val_loss: 0.0035 - val_acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69f0cbaf60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=4, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.00346304196436\n",
      "Test accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract model and save weights to a .mat file\n",
    "weights = model.get_weights()\n",
    "\n",
    "# write individual layers to a dictionary\n",
    "weight_dict = {}\n",
    "# initiate counters\n",
    "layer_count = 0\n",
    "bias_count = 0\n",
    "for i, layer in enumerate(weights):\n",
    "    # sort into odd and even indices\n",
    "    if i%2 == 0:\n",
    "        layer_count += 1\n",
    "        weight_dict['weights_{0}'.format(layer_count)] = weights[i]\n",
    "    else:\n",
    "        bias_count += 1\n",
    "        weight_dict['biases_{0}'.format(bias_count)] = weights[i]\n",
    "\n",
    "# save weights and biases into .mat file\n",
    "io.savemat('./weights.mat',weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save MNIST data to a .mat file\n",
    "test_data = {\n",
    "    'X_test':X_test,\n",
    "    'Y_test':Y_test\n",
    "}\n",
    "\n",
    "io.savemat('./test_data.mat', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract model and save weights to a .mat file\n",
    "weights = model.get_weights()\n",
    "W1 = weights[0]\n",
    "B1 = weights[1]\n",
    "W2 = weights[2]\n",
    "B2 = weights[3]\n",
    "W3 = weights[4]\n",
    "B3 = weights[5]\n",
    "\n",
    "X1 = X_test[10,:]\n",
    "\n",
    "X2 = np.matmul(np.transpose(W1), X1)+ B1\n",
    "X2[X2 < 0] = 0\n",
    "X3 = np.matmul(np.transpose(W2), X2) + B2\n",
    "X3[X3 <0] = 0\n",
    "X4 = np.matmul(np.transpose(W3), X3) + B3\n",
    "np.argmax(X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADkRJREFUeJzt3X+QXXV5x/HPY7LZxWBbIhDWJNOAE1DMDFF2IoPUQqkZ\nYGgT/BFJWyfa1KBCp87YsUixQsfWDK2orUpdJZPoUIwamMQZ/EG3Mqljh7CkMQkJkEiXkjRkYcI0\nwZHNJnn6x57gEvZ8782959xz7z7v18zO3nuee+559sIn597zved8zd0FIJ7XVN0AgGoQfiAowg8E\nRfiBoAg/EBThB4Ii/EBQhB8IivADQU1t5camWbf3aHorNwmE8pJ+qSM+YvU8tqnwm9lVkr4kaYqk\nb7j7qtTjezRdb7crm9kkgISHfaDuxzb8tt/Mpkj6iqSrJV0oaZmZXdjo8wForWY+8y+UtMfdn3L3\nI5K+LWlxMW0BKFsz4Z8l6Zlx9/dmy17BzFaa2aCZDY5qpInNAShS6Uf73b3f3fvcva9L3WVvDkCd\nmgn/Pklzxt2fnS0D0AGaCf8jkuaZ2blmNk3S9ZI2FtMWgLI1PNTn7kfN7CZJP9LYUN9qd3+ssM4A\nlKqpcX53f0DSAwX1AqCF+HovEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0G1dIputN6U3/rNZP2JL5+XrD9+xTeS\n9VuHL07Wt//x+bm1YzufTK6LcrHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmhrnN7MhSYclHZN0\n1N37imgKxTl+7uxkffvlX0vWRz39/J89+9Fk/aLrLs2tzWGcv1JFfMnnCnd/voDnAdBCvO0Hgmo2\n/C7px2b2qJmtLKIhAK3R7Nv+y9x9n5mdLelBM3vc3TeNf0D2j8JKSerRa5vcHICiNLXnd/d92e9h\nSfdLWjjBY/rdvc/d+7rU3czmABSo4fCb2XQze92J25IWSdpRVGMAytXM2/6Zku43sxPP86/u/sNC\nugJQuobD7+5PSbqowF7QoKlz8sfyz+3f08JO0EkY6gOCIvxAUIQfCIrwA0ERfiAowg8ExaW7O8D/\n/E3+abGSdPFVO3Nrd/T+R9HtnJLTL30ut/bMp9N/15nbjibrp23Y3FBPGMOeHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCYpy/A2y74Z+T9VE/1qJOTt1DF92TX6xxQvj9v+xN1lcfXpKsT/339GXFo2PP\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc7fBroeSo9nd9mUFnVy6v7ryPFkfWj0rNzaddMPJtdd\nevpwuv6t/mT92lkXJ+vRsecHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBqjvOb2WpJ10oadvf52bIZ\nktZJmitpSNJSd3+hvDY726+WLEzWP9T73WS91vn6ZZ7PP3/gI8n6WQPdyXr3/+X39qnL0/ue7e/7\np2S9lr2fyp8XYPbnftbUc08G9ez510i66qRlN0sacPd5kgay+wA6SM3wu/smSSd/FWuxpLXZ7bWS\n0pdUAdB2Gv3MP9Pd92e3n5U0s6B+ALRI0wf83N0leV7dzFaa2aCZDY5qpNnNAShIo+E/YGa9kpT9\nzj0Dw9373b3P3fu6lD44BKB1Gg3/RknLs9vLJW0oph0ArVIz/GZ2r6T/lHSBme01sxWSVkl6l5nt\nlvT72X0AHaTmOL+7L8spXVlwLx1rylsuSNY/e2f6vPO+aUdqbeEUO/q1Wte+v/Un70nW3/zJx5P1\nY4cOnXJPJ1yw+/xkffMf9iTrC7tfStZ/8NE7cmuLej6ZXHfu36ev+e8jnX/8im/4AUERfiAowg8E\nRfiBoAg/EBThB4Li0t0FOD4t/TLWHsprzp8+ffJJl792+P2nJdc9f+/mZL3Myb+P7XwyWf/YmvTp\nxIM3fDFZ752S/7dvWZFe9z33LU/W/ee7kvVOwJ4fCIrwA0ERfiAowg8ERfiBoAg/EBThB4JinL8D\n3HKgL1k/9Gevz60d27u76HZaZu7655P1Ty+5JFlfdc4jRbYz6bDnB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgGOdvgS5r/NLbkrTtbbmzoWU6dyw/ySxZnvqa48l6M6/7/96erp8zCaamZc8PBEX4gaAI\nPxAU4QeCIvxAUIQfCIrwA0HVHOc3s9WSrpU07O7zs2W3SfqwpOeyh93i7g+U1WS7e+Kjr03WR73M\nq99PXkPvzr9OgSR976z0nAOjnj/OX+u/yRs+kywr/Q2DzlDPnn+NpIlmhfiCuy/IfsIGH+hUNcPv\n7pskHWxBLwBaqJnP/DeZ2TYzW21mZxTWEYCWaDT8d0l6o6QFkvZL+nzeA81spZkNmtngqEYa3ByA\nojUUfnc/4O7H3P24pK9LWph4bL+797l7X5e6G+0TQMEaCr+Z9Y67e52kHcW0A6BV6hnqu1fS5ZLO\nNLO9kj4j6XIzWyDJJQ1JuqHEHgGUoGb43X3ZBIvvLqGXjnXr73y/6hba1tQ5s3Nrhy9+Q3Ldf/nQ\nV4tu52WbR3qSdTtytLRttwu+4QcERfiBoAg/EBThB4Ii/EBQhB8Iikt3o1Q7bz8nt/bYoi+Xuu31\nL56ZW7vrL9+XXLdnV/p04cmAPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4P5rS9VBvsv653vUt\n6uTV1uy7NLfW8/3JP45fC3t+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4CTLH0hM1dlj9VdD0O\n/dElDa97+9+mr7J+xWkvNfzcUu2/LT0VdnOvSy3+e/tKff5Ox54fCIrwA0ERfiAowg8ERfiBoAg/\nEBThB4KqOc5vZnMkfVPSTEkuqd/dv2RmMyStkzRX0pCkpe7+Qnmttq9V696brC9d8cWmnn/TP3wl\nWU+PpaeNesOr1vn8jfdWy/yBjyTr87SltG1PBvXs+Y9K+oS7XyjpEkk3mtmFkm6WNODu8yQNZPcB\ndIia4Xf3/e6+Jbt9WNIuSbMkLZa0NnvYWklLymoSQPFO6TO/mc2V9FZJD0ua6e77s9KzGvtYAKBD\n1B1+Mztd0npJH3f3Q+Nr7u4aOx4w0XorzWzQzAZHNdJUswCKU1f4zaxLY8G/x93vyxYfMLPerN4r\naXiidd2939373L2vS91F9AygADXDb2Ym6W5Ju9z9znGljZKWZ7eXS9pQfHsAylLPKb3vkPQBSdvN\nbGu27BZJqyR9x8xWSHpa0tJyWmx/5617Plnf/Cc9yfrC7uZOq21nm0fy//b+Z383ue4LH8uf3luS\n3vTfe5L18gYZJ4ea4Xf3n0qynPKVxbYDoFX4hh8QFOEHgiL8QFCEHwiK8ANBEX4gKBv7Zm5r/IbN\n8LdbvNHBXy1emKw/8wfpS38/efXXkvUyT5utpdaluy/66p/n1ub83c+Kbie8h31Ah/xg3tD8K7Dn\nB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmKK7BU7bsDlZP7/GZVDeuezGZL3rgwdyaz98y7rkuot2\nXJ+sH19zdrLuNUaU5259LrfG+fbVYs8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0FxPj8wiXA+P4Ca\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gqJrhN7M5ZvYTM9tpZo+Z2V9ky28zs31mtjX7uab8dgEUpZ6L\neRyV9Al332Jmr5P0qJk9mNW+4O7/WF57AMpSM/zuvl/S/uz2YTPbJWlW2Y0BKNcpfeY3s7mS3irp\n4WzRTWa2zcxWm9kZOeusNLNBMxsc1UhTzQIoTt3hN7PTJa2X9HF3PyTpLklvlLRAY+8MPj/Reu7e\n7+597t7Xpe4CWgZQhLrCb2ZdGgv+Pe5+nyS5+wF3P+buxyV9XVJ6NkoAbaWeo/0m6W5Ju9z9znHL\ne8c97DpJO4pvD0BZ6jna/w5JH5C03cy2ZstukbTMzBZIcklDkm4opUMApajnaP9PJU10fvADxbcD\noFX4hh8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiColk7R\nbWbPSXp63KIzJT3fsgZOTbv21q59SfTWqCJ7+213P6ueB7Y0/K/auNmgu/dV1kBCu/bWrn1J9Nao\nqnrjbT8QFOEHgqo6/P0Vbz+lXXtr174kemtUJb1V+pkfQHWq3vMDqEgl4Tezq8zsCTPbY2Y3V9FD\nHjMbMrPt2czDgxX3strMhs1sx7hlM8zsQTPbnf2ecJq0inpri5mbEzNLV/ratduM1y1/229mUyQ9\nKeldkvZKekTSMnff2dJGcpjZkKQ+d698TNjM3inpRUnfdPf52bI7JB1091XZP5xnuPtftUlvt0l6\nseqZm7MJZXrHzywtaYmkD6rC1y7R11JV8LpVsedfKGmPuz/l7kckfVvS4gr6aHvuvknSwZMWL5a0\nNru9VmP/87RcTm9twd33u/uW7PZhSSdmlq70tUv0VYkqwj9L0jPj7u9Ve0357ZJ+bGaPmtnKqpuZ\nwMxs2nRJelbSzCqbmUDNmZtb6aSZpdvmtWtkxuuiccDv1S5z97dJulrSjdnb27bkY5/Z2mm4pq6Z\nm1tlgpmlX1bla9fojNdFqyL8+yTNGXd/drasLbj7vuz3sKT71X6zDx84MUlq9nu44n5e1k4zN080\ns7Ta4LVrpxmvqwj/I5Lmmdm5ZjZN0vWSNlbQx6uY2fTsQIzMbLqkRWq/2Yc3Slqe3V4uaUOFvbxC\nu8zcnDeztCp+7dpuxmt3b/mPpGs0dsT/F5L+uooecvo6T9LPs5/Hqu5N0r0aexs4qrFjIyskvV7S\ngKTdkv5N0ow26u1bkrZL2qaxoPVW1NtlGntLv03S1uznmqpfu0RflbxufMMPCIoDfkBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QFOEHgvp/YSlVkx6DavkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16205a5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X1.reshape((28,28))\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
